{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Question 9\n",
    "Image classification task using Niave Bayes and logistic regression classifier. \n",
    "1. Download a dataset from https://www.kaggle.com/c/dogs-vs-cats/data . (2 points)\n",
    "2. Randomly sample the images to create a cat and dog training sets consisting of 70% of the images. Rest 30% images form the testing images. (1 point)\n",
    "3. Build Naive Bayes classifier for cat and dog images. Use intensity and SVD based features for these classifiers. (2 points)\n",
    "4. Build a logistic regression based classifier for cat and dog images. Use intensity and SVD based features for these classifiers. (2 points)\n",
    "5. Calculate accuracy for the training set and testing set for the above classifiers, for both intensity and SVD based features and confusion matrix. (4 points)\n",
    "7. Compare the performance of the above classifiers and report your observations. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleSubmission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
      "test1.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
      "train.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "##Question 9 Part 1\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "import sys\n",
    "\n",
    "## Import kaggle config (username and API KEY)from ~/.kaggle/kaggle.json\n",
    "api  = KaggleApi()\n",
    "api.authenticate()\n",
    "dirname = os.getcwd()\n",
    "filename = os.path.join(dirname, 'data')\n",
    "api.competition_download_files('dogs-vs-cats',path=filename,force=False,quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract archive files (train.zip and test1.zip) to ./data\n",
    "import zipfile\n",
    "os.chdir(filename)\n",
    "abs_list_of_files_name = []\n",
    "for item in os.listdir(filename):\n",
    "    if zipfile.is_zipfile(item):\n",
    "        with zipfile.ZipFile(item, 'r') as file:\n",
    "            for member in file.infolist():\n",
    "                if member.filename[-1] == '/':\n",
    "                    continue\n",
    "                abs_list_of_files_name.append(filename + \"/\" + member.filename)\n",
    "            file.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "## Get from absolute files names class label for the image\n",
    "import re\n",
    "training_list = []\n",
    "test_list = []\n",
    "for elem in abs_list_of_files_name :\n",
    "    train_match = re.search(r'train',elem)\n",
    "    if train_match:\n",
    "        training_list.append(elem)\n",
    "    test_match = re.search(r'test1',elem)\n",
    "    if test_match:\n",
    "        test_list.append(elem) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [filepath, filename, category]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a trainng catalog dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Convert List to 1D numpy Array\n",
    "train_list_1darray = np.array(training_list)\n",
    "training_df = pd.DataFrame(train_list_1darray,columns=['filepath']) \n",
    "training_df['filename'],training_df['category'] = training_df['filepath'].apply(lambda x: os.path.basename(x)),training_df['filepath'].apply(lambda x: os.path.basename(x).split('.')[0])\n",
    "#training_df[~training_df['category'].isin(['cat','dog'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a test catalog dataset\n",
    "test_list_1darray = np.array(test_list) \n",
    "test_df = pd.DataFrame(test_list_1darray,columns=['filepath']) \n",
    "test_df['filename'],test_df['category'] = test_df['filepath'].apply(lambda x: os.path.basename(x)),test_df['filepath'].apply(lambda x: os.path.basename(x).split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Feature extraction from a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing\n",
    "from skimage.feature import local_binary_pattern, greycomatrix, greycoprops\n",
    "from skimage.filters import gabor\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a list of tuples of (height,width) for all images\n",
    "##import opencv library\n",
    "import cv2\n",
    "\n",
    "## Returns tuple \n",
    "##output: the image height,width\n",
    "\n",
    "def image_dimensions(imgloc):\n",
    "    img = cv2.imread(imgloc)\n",
    "    return (img.shape[0],img.shape[1])\n",
    "\n",
    "training_img_2Ddimension = [image_dimensions(x) for x in training_df['filepath']]\n",
    "test_img_2Ddimension = [image_dimensions(x) for x in test_df['filepath']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## logic to resize the images\n",
    "## automate to select proper height and width\n",
    "## start with an initial height width \n",
    "## iteriate to adjust if discard ratio > 0.01\n",
    "## if discard_ratio > 0.01 then height = 0.9 * height and width = width * 0.9\n",
    "\n",
    "import math\n",
    "def resize_height_width(result,ratio):\n",
    "    discard_ratio = 0\n",
    "    fixed_height_to_resize = 500\n",
    "    fixed_width_to_resize = 500\n",
    "    discard_list = []\n",
    "    while True:\n",
    "        outlist = [ 1 if x[0] >=fixed_height_to_resize and x[1] >= fixed_width_to_resize else 0 for x in result]\n",
    "        discard_ratio = outlist.count(0) / outlist.count(1)\n",
    "        if discard > ratio :\n",
    "            fixed_width_to_resize  = math.floor(0.9 * fixed_width_to_resize)\n",
    "            fixed_height_to_resize = math.floor(0.9 * fixed_height_to_resize)\n",
    "        else:\n",
    "            discard_list = outlist\n",
    "            break\n",
    "    return discard_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add a dataframe column(include) to track if a image is resizeable or rejected for a height width \n",
    "discard_list = []\n",
    "discard_list = resize_height_width(training_img_2Ddimension,0.001)\n",
    "training_df['include'] = pd.Series(discard_list).values\n",
    "## copy original dataframe to create a subset dataframe for all image that have include = 1\n",
    "training_df_subset = training_df[training_df['include']==1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add a dataframe column(include) to track if a image is resizeable or rejected for a height width \n",
    "discard_list = []\n",
    "discard_list = resize_height_width(test_img_2Ddimension,0.001)\n",
    "test_df['include'] = pd.Series(discard_list).values\n",
    "## copy original dataframe to create a subset dataframe for all image that have include = 1\n",
    "test_df_subset = training_df[training_df['include']==1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resize image to fixed_width_to_resize , fixed_height_to_resize \n",
    "## convert to grayscale \n",
    "## return singular numpy 1Darray\n",
    "def image_resize_convert(imgpath,fixed_height_to_resize,fixed_width_to_resize):\n",
    "    img = Image.open(imgpath)\n",
    "    img = img.resize((fixed_height_to_resize, fixed_width_to_resize))\n",
    "    imggray = img.convert('L')\n",
    "    filename = os.path.basename(imgpath)\n",
    "    filepath = os.path.dirname(imgpath)\n",
    "    newfilepath = filepath + \"/100_\" +filename \n",
    "    #new_image.save(newfilepath)\n",
    "    imgmat = np.array(list(imggray.getdata(band=0)), float)\n",
    "    imgmat.shape = (fixed_height_to_resize, fixed_width_to_resize)\n",
    "    imgmat = np.matrix(imgmat)\n",
    "    U, sigma, V = np.linalg.svd(imgmat)\n",
    "    img.close()\n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a numpy 1D array list of singular values \n",
    "global_SVD = [image_resize_convert(x,fixed_height_to_resize,fixed_width_to_resize) for x in newdf['filepath']]\n",
    "## label list\n",
    "global_label = [ os.path.basename(x).split('.')[0] for x in newdf['filepath'] ]\n",
    "global_category = [ 1 if x == 'cat' else 0 for x in global_label]\n",
    "## Convert to dataframe \n",
    "## Normalize the dataframe\n",
    "## Assign label to each row in dataframe\n",
    "train_numpy_2darray = np.array(global_SVD)\n",
    "train_numpy_2darray_normalized = preprocessing.normalize(train_numpy_2darray, norm='l2')\n",
    "#train_svd_df = pd.DataFrame(train_numpy_2darray_normalized)\n",
    "#train_svd_df['category'] = pd.Series(global_category).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_category_1darray = np.array(global_category) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries for training models\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "##--------------------\n",
    "## tunable-parameters\n",
    "##--------------------\n",
    "test_size = 0.10\n",
    "seed      = 9\n",
    "scoring   = \"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model using train_numpy_2darray_normalized  and global_category\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state=seed)))\n",
    "models.append(('NB', GaussianNB()))\n",
    "\n",
    "## variables to hold the results and names\n",
    "results = []\n",
    "names   = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] features shape: (24825, 99)\n",
      "[STATUS] labels shape: (24825,)\n",
      "[STATUS] training started...\n"
     ]
    }
   ],
   "source": [
    "# verify the shape of the feature vector and labels\n",
    "print(\"[STATUS] features shape: {}\".format(train_numpy_2darray_normalized.shape))\n",
    "print(\"[STATUS] labels shape: {}\".format(train_category_1darray.shape))\n",
    "\n",
    "print(\"[STATUS] training started...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.444706 (0.037895)\n",
      "NB: 0.601850 (0.214963)\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross validation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = cross_val_score(model, train_numpy_2darray_normalized, train_category_1darray, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Machine Learning algorithm comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------\n",
    "# TESTING OUR MODEL\n",
    "#https://gogul09.github.io/software/image-classification-python\n",
    "#https://hadrienj.github.io/posts/Deep-Learning-Book-Series-2.8-Singular-Value-Decomposition/\n",
    "#https://learning.oreilly.com/library/view/mastering-opencv-4/9781789344912/9c91ee0b-2fab-4972-a4d5-f3e6cdae8c47.xhtml\n",
    "#https://www.frankcleary.com/svdimage/\n",
    "#https://auth0.com/blog/image-processing-in-python-with-pillow/\n",
    "#-----------------------------------\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "# fit the model with data\n",
    "logreg.fit(train_numpy_2darray_normalized, train_category_1darray)\n",
    "\n",
    "#y_pred=logreg.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
